---
title: AI Copilot
emoji: ü§ñ
colorFrom: blue
colorTo: indigo
sdk: gradio
sdk_version: 6.0.1
app_file: app/app.py
pinned: false
---

# AI Copilot ‚Äî MVP 

**Autor:** Marisol S. Herrera

**Fecha:** Diciembre 2025

AI Copilot es un MVP de asistente conversacional dise√±ado para demostrar integraci√≥n con un LLM abierto (Llama 4 Maverick v√≠a Groq), implementando l√≥gica conversacional controlada, seguridad, manejo de intents y recuperaci√≥n de contexto a corto plazo.
El sistema responde a necesidades de tareas diarias, b√∫squedas r√°pidas de informaci√≥n y apoyo educativo/productivo

## **1. Objetivo del Proyecto**
Construir un asistente conversacional con:

- Integraci√≥n estable con LLM (Groq).

- Control avanzado de timeouts, reintentos y fallbacks.

- Memoria conversacional corta y truncado de historial.

- Manejo de intents simples (/nota, /recordatorio, /busqueda, etc.)

- Guardrails de seguridad.
    
- M√©tricas de desempe√±o en latencia, uso de token y manejo de errores

## **2. Arquitectura del MVP**
    /core
        prompting.py        ‚Üí Plantillas system/user/assistant y truncado.
        conversation.py     ‚Üí Manejo del historial, intents y pipeline conversacional.
    
    /services
        llm.py              ‚Üí Cliente Groq (timeouts, retries, errores, m√©tricas).
    
    /app
        app.py              ‚Üí Interfaz Gradio para web demo.
    
    /tests
        test_prompting.py
        test_conversation.py
        test_llm.py
    
    .env.example            ‚Üí Variables de entorno (sin claves reales).
    README.md

## **3. Setup & Ejecuci√≥n Local**
**Instalar dependencias**
    pip install -r requirements.txt

**Variales de entorno**

Copiar .env.example ‚Üí .env y colocar:

        GROQ_API_KEY="TU_LLAVE_AQUI"
        MODEL_NAME="meta-llama/llama-4-maverick-17b-128e-instruct"

## **4. Integraci√≥n LLM**
**Modelo**
- meta-llama/llama-4-maverick-17b-128e-instruct
- Este modelo se eligi√≥ porque ofrece un balance s√≥lido entre capacidad de razonamiento y baja latencia, gracias a su arquitectura optimizada (128E) para ejecuci√≥n r√°pida en Groq.
Al ser una versi√≥n instruct-tuned, sigue comandos con alta precisi√≥n y mantiene respuestas seguras y coherentes, lo cual es ideal para un asistente con intents estructurados y memoria corta.


- Menor latencia, m√°s estable, econ√≥mico, perfecto para MVP.

**Par√°metros de inferencia**

- `temperature = 0.3` ‚Üí Respuestas estables y predecibles

- `top_p = 0.9` ‚Üí Variabilidad controlada

- `max_tokens` = 300 ‚Üí Limita costos

- `seed = 42` ‚Üí Reproducibilidad

**Control de fallos**
Implementado en `services/llm.py`:


| Error              | Acci√≥n                                |
| ------------------ | ------------------------------------- |
| 400                | No retry, fallback inmediato          |
| 401 / 403          | Fallback inmediato, mensaje claro     |
| 500 / 503          | Retry con backoff exponencial (max 2) |
| Timeout            | Tratado como 500 ‚Üí retry              |
| Exception gen√©rica | Fallback seguro                       |

## **5. L√≥gica de conversaci√≥n**
**Memoria**

Se conservan los √∫ltimos ~5 turnos (contexto corto).
L√≠mite de sesi√≥n: **20 turnos.**

**Intents soportados**

- `/nota` <texto>

- `/recordatorio` <texto>

- `/agenda`

- `/vernota` <texto>

- `/busqueda` <texto>

- Flujo por defecto si no coincide con un intent.

**Guardrails**

Antes de contactar al LLM:

- violencia extrema

- autoharm

- instrucciones ilegales (ej. bombas)

El sistema bloquea con:

    Lo siento, no puedo ayudar con esa solicitud.

## **6. Pruebas**

El proyecto se valid√≥ mediante pruebas unitarias, pruebas de integraci√≥n simulando errores del proveedor, y tres corridas E2E completas ejecutadas en entorno local.
A continuaci√≥n se documentan los resultados con precisi√≥n.

### **6.1. Pruebas Unitarias**

**Prompting**

- System prompt siempre presente ‚úî 
- Truncado correcto del historial ‚úî 
- Inserci√≥n ordenada de mensajes (system ‚Üí history ‚Üí user) ‚úî 

**ConversationManager**

- update_state mantiene solo √∫ltimos N turnos ‚úî 
- pipeline detecta intents correctamente ‚úî 
- reconoce /nota, /agenda, /busqueda, etc. ‚úî 

**LLM**

- Test 400: retorna fallback sin retry ‚úî 
- Test 500: retry, luego fallback ‚úî 
- Test timeout: retry ‚Üí fallback ‚úî 
- Test clave inv√°lida: error 401 ‚Üí fallback inmediato ‚úî 
- Test success: devuelve contenido del modelo ‚úî 

***Resultado:**
**TODAS las pruebas unitarias pasan.**

### **6.2 Pruebas E2E**

### **0. Prueba con API inv√°lida**

        GROQ_API_KEY="INVALID_TEST_KEY" python3 app/app.py  

**Salida esperada y obtenida:**
- Log:

        INTENT | ... | Intent resolved: DEFAULT
        FALLBACK | ... | LLM service unavailable


- Mensaje al usuario:

    ‚ö†Ô∏è Modo fallback activado
    Hubo un problema al conectarme con el modelo...


- M√©tricas:

    - total_calls: 1
    - total_fallbacks: 1
    - retries: 0
    - latency: 0 ms


**Validaci√≥n de:**

- Manejo correcto de clave inv√°lida (401‚Äì403).

- Fallback visible + log en consola.

### **1. Conversaci√≥n larga, 20 turnos**
Secuencia validada:

**Memoria de identidad**

- ‚ÄúMe llamo Marisol‚Äù ‚Üí guardada.

- ‚Äú¬øC√≥mo me llamo?‚Äù ‚Üí ‚ÄúTe llamas Marisol.‚Äù

**Creaci√≥n y recuperaci√≥n de notas**

- `/nota Contrase√±a Ticketmaster sosososos ‚Ä¶`

- Recuperada correctamente con `/vernota Ticketmaster`.

**Recordatorios con fecha**

- `/recordatorio Expo Ingenier√≠as‚Ä¶`

- `Posteriormente visible en /agenda.`

**Intentos de contenido inseguro**

- ‚Äúc√≥mo hago un explosivo casero?‚Äù

- Log:

        BLOCKED | req=... | Blocked unsafe input


- Respuesta:

        Lo siento, no puedo ayudar con esa solicitud.

**Turn limit**

- En turno 17‚Äì20:

 - Advertencias: ‚ÄúQuedan 3 turnos‚Ä¶‚Äù

 - Reinicio autom√°tico en turno 20.

 - Nuevo turno inicia en `[Turno 1/20]`.


**Validaciones cubiertas**

- Memoria corta funcional

- Coherencia pos 8+ turnos

- Manejo del l√≠mite de sesi√≥n

- Guardrails de seguridad

### **Conclusi√≥n General de Pruebas**

| Requisito                                                                | Estado                     |
| ------------------------------------------------------------------------ | -------------------------- |
| Memoria corta tipo chat                                                  | ‚úî Cumplido                 |
| Intents funcionales (/nota, /recordatorio, /agenda, /vernota, /busqueda) | ‚úî Cumplido                 |
| Coherencia tras 8+ turnos                                                | ‚úî Validado en corridas 1‚Äì3 |
| Manejo de l√≠mites de sesi√≥n                                              | ‚úî Validado                 |
| Fallback ante API inv√°lida                                               | ‚úî Validado                 |
| Guardrails para contenido peligroso                                      | ‚úî Validado                 |
| M√©tricas reales de LLM                                                   | ‚úî Registradas              |
| Pruebas unitarias (prompting, conversation, llm)                         | ‚úî 100% passing             |


## **7. M√©tricas**

A continuaci√≥n se presentan los resultados de tres corridas independientes ejecutadas en entorno local. Las m√©tricas corresponde a: 

- latencia promedio

- p50 / p95

- reintentos

- fallbacks

- tokens utilizados

- total de llamadas al modelo

**Tabla de M√©tricas por Corrida**

| Corrida                                  | Total Calls | Avg Latency (ms) | p50 (ms) | p95 (ms) | Retries | Fallbacks | Total Tokens |
| ---------------------------------------- | ----------- | ---------------- | -------- | -------- | ------- | --------- | ------------ |
| **Run 0** (API inv√°lida / fallback test) | 1           | 0                | 0        | 0        | 0       | **1**     | 0            |
| **Run 1**                                | 18          | 468.85           | 348.70   | 1315.61  | 0       | 0         | 7522         |
| **Run 2**                                | 20          | 794.77           | 399.69   | 1836.00  | 0       | 0         | 8592         |
| **Run 3**                                | 11          | 482.43           | 471.73   | 592.67   | 0       | 0         | 4965         |


## **8. Limitaciones Actuales**

- No existe persistencia real (solo memoria de sesi√≥n en RAM).

- La agenda y notas se pierden tras reinicio.

- No soporta attachments, im√°genes o documentos.

- B√∫squeda sem√°ntica no implementada (solo respuestas directas del LLM).

- El throttling/token budgeting es b√°sico.

- No implementa multillamadas o herramientas externas (Bing, Wikipedia, etc.).

## **9. Posibles Mejoras**

- Persistencia real (SQLite o TinyDB)

-An√°lisis de documentos (PDF, im√°genes)

- Integraci√≥n con herramientas externas (Wikipedia API)

- UX mejorada con componentes adicionales en Gradio

- Historial ampliado mediante res√∫menes autom√°ticos

- Endpoint `/health` para exponer m√©tricas en JSON 